{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimplePendulumEnv:\n",
    "    def __init__(self):\n",
    "        self.g = 9.8  # acceleration due to gravity in m/s^2\n",
    "        self.l = 1.0  # length of the pendulum in meters\n",
    "        self.m = 1.0  # mass of the pendulum bob in kg\n",
    "        self.dt = 0.05  # time step in seconds\n",
    "        self.theta = 0.0  # pendulum angle from the vertical (in radians)\n",
    "        self.theta_dot = 0.0  # pendulum angular velocity\n",
    "        \n",
    "        # Action space bounds\n",
    "        self.max_torque = 2.0\n",
    "        \n",
    "        # Observation space bounds\n",
    "        self.max_speed = 8  # Arbitrary bound on angular velocity\n",
    "        \n",
    "        # For rendering\n",
    "        self.fig, self.ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, -self.max_torque, self.max_torque)[0]\n",
    "        theta_ddot = (-self.g / self.l) * np.sin(self.theta) + (1 / (self.m * self.l ** 2)) * action\n",
    "        self.theta_dot = np.clip(self.theta_dot + theta_ddot * self.dt, -self.max_speed, self.max_speed)\n",
    "        self.theta += self.theta_dot * self.dt\n",
    "        self.theta = self._normalize_angle(self.theta)\n",
    "        \n",
    "        # Calculate reward (for simplicity: penalize the deviation from the upright position)\n",
    "        reward = -((self.theta ** 2) + (0.1 * self.theta_dot ** 2) + (0.001 * (action ** 2)))\n",
    "        \n",
    "        # Observation is the new state\n",
    "        observation = np.array([self.theta, self.theta_dot])\n",
    "        return observation, reward, False, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.theta = np.random.uniform(-np.pi, np.pi)\n",
    "        self.theta_dot = np.random.uniform(-1, 1)\n",
    "        return np.array([self.theta, self.theta_dot])\n",
    "    \n",
    "    def render(self):\n",
    "        if self.fig is None:\n",
    "            # plt.ion()\n",
    "            self.fig, self.ax = plt.subplots(figsize=(5, 5))\n",
    "        \n",
    "        self.ax.clear()\n",
    "        x = np.sin(self.theta) * self.l\n",
    "        y = -np.cos(self.theta) * self.l\n",
    "        self.ax.plot([0, x], [0, y], marker='o')\n",
    "        self.ax.set_xlim(-self.l, self.l)\n",
    "        self.ax.set_ylim(-self.l, self.l)\n",
    "        self.ax.set_aspect('equal', 'box')\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)\n",
    "    \n",
    "    def _normalize_angle(self, theta):\n",
    "        \"\"\"Normalize the angle to be within [-pi, pi]\"\"\"\n",
    "        return ((theta + np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "# Example of using the environment\n",
    "env = SimplePendulumEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.array([0.1])  # Example action: small constant torque\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "class SimplePendulumEnv:\n",
    "    def __init__(self):\n",
    "        self.g = 9.8  # acceleration due to gravity in m/s^2\n",
    "        self.l = 1.0  # length of the pendulum in meters\n",
    "        self.m = 1.0  # mass of the pendulum bob in kg\n",
    "        self.dt = 0.05  # time step in seconds\n",
    "        self.theta = 0.0  # pendulum angle from the vertical (in radians)\n",
    "        self.theta_dot = 0.0  # pendulum angular velocity\n",
    "        \n",
    "        # Action space bounds\n",
    "        self.max_torque = 2.0\n",
    "        \n",
    "        # Observation space bounds\n",
    "        self.max_speed = 8  # Arbitrary bound on angular velocity\n",
    "\n",
    "        # # For rendering\n",
    "        # self.fig, self.ax = plt.subplots(figsize=(5, 5))\n",
    "        # self.line, = self.ax.plot([], [], marker='o')  # Initialize a blank line\n",
    "        # self.ax.set_xlim(-self.l, self.l)\n",
    "        # self.ax.set_ylim(-self.l, self.l)\n",
    "        # self.ax.set_aspect('equal', 'box')\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, -self.max_torque, self.max_torque)[0]\n",
    "        theta_ddot = (-self.g / self.l) * np.sin(self.theta) + (1 / (self.m * self.l ** 2)) * action\n",
    "        self.theta_dot = np.clip(self.theta_dot + theta_ddot * self.dt, -self.max_speed, self.max_speed)\n",
    "        self.theta += self.theta_dot * self.dt\n",
    "        self.theta = self._normalize_angle(self.theta)\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = -((self.theta ** 2) + (0.1 * self.theta_dot ** 2) + (0.001 * (action ** 2)))\n",
    "        \n",
    "        # Observation is the new state\n",
    "        observation = np.array([self.theta, self.theta_dot])\n",
    "        return observation, reward, False, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.theta = np.random.uniform(-np.pi, np.pi)\n",
    "        self.theta_dot = np.random.uniform(-1, 1)\n",
    "        return np.array([self.theta, self.theta_dot])\n",
    "    \n",
    "    def render(self, ax=None) -> None:\n",
    "\n",
    "        plt.cla()\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        plt.axis('equal')\n",
    "\n",
    "        x = np.sin(self.theta) * self.l\n",
    "        y = -np.cos(self.theta) * self.l\n",
    "        plt.scatter([0, x], [0, y])\n",
    "\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    \n",
    "    def _normalize_angle(self, theta):\n",
    "        \"\"\"Normalize the angle to be within [-pi, pi]\"\"\"\n",
    "        return ((theta + np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "env = SimplePendulumEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "while not done:\n",
    "    action = np.array([0.1])  # Example action: small constant torque\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CartPoleEnv:\n",
    "    def __init__(self):\n",
    "        # Constants\n",
    "        self.gravity = 9.8\n",
    "        self.mass_cart = 2.0\n",
    "        self.mass_pole = 0.1\n",
    "        self.total_mass = self.mass_cart + self.mass_pole\n",
    "        self.length = 1  # Half the pole's length\n",
    "        self.polemass_length = self.mass_pole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.dt = 0.01  # Time step\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 10\n",
    "\n",
    "        # State: [cart position, cart velocity, pole angle, pole velocity at tip]\n",
    "        self.state = None\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = f\"{action} invalid. Action must be either 0 (left) or 1 (right).\"\n",
    "        assert action in [0, 1], err_msg\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the sake of simplicity, we'll ignore some dynamics\n",
    "        temp = (force + self.polemass_length * theta_dot**2 * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (self.length * (4.0/3.0 - self.mass_pole * costheta**2 / self.total_mass))\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        # Update the state\n",
    "        x += self.dt * x_dot\n",
    "        x_dot += self.dt * xacc\n",
    "        theta += self.dt * theta_dot\n",
    "        theta_dot += self.dt * thetaacc\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        # done = x < -self.x_threshold \\\n",
    "        #        or x > self.x_threshold \\\n",
    "        #        or theta < -self.theta_threshold_radians \\\n",
    "        #        or theta > self.theta_threshold_radians\n",
    "\n",
    "        reward = 0 if done else 1\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        return np.array(self.state)\n",
    "    \n",
    "    def render(self, ax=None) -> None:\n",
    "\n",
    "        plt.cla()\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        plt.axis('equal')\n",
    "\n",
    "        x, _, theta, _ = self.state\n",
    "\n",
    "        # Draw cart\n",
    "        cart_width = 0.3\n",
    "        cart_height = 0.2\n",
    "        pole_width = 0.05\n",
    "        pole_len = 1.0 * self.length  # Displayed pole length\n",
    "\n",
    "        cart_x = x - cart_width / 2\n",
    "        cart_y = 0 - cart_height / 2\n",
    "        pole_x = x\n",
    "        pole_y = 0\n",
    "        pole_theta = theta - np.pi / 2  # Convert to right triangle\n",
    "\n",
    "        ax.add_patch(plt.Rectangle((cart_x, cart_y), cart_width, cart_height, color='blue'))\n",
    "        ax.plot([pole_x, pole_x + np.cos(pole_theta) * pole_len], [pole_y, pole_y + np.sin(pole_theta) * pole_len], linewidth=2, color='red')\n",
    "\n",
    "        ax.set_xlim(-self.x_threshold * 1.2, self.x_threshold * 1.2)\n",
    "        ax.set_ylim(-self.length * 1.2, self.length * 1.2)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "# Example usage\n",
    "env = CartPoleEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = np.random.choice([0, 1])  # Random action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
